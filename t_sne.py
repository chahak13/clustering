# -*- coding: utf-8 -*-
"""t-SNE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jwjLFywYupj4dQmjuXQsIohBePgnspX_
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from PIL import Image
from torchvision.datasets import CIFAR10
from sklearn.cluster import KMeans
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import homogeneity_score
import pandas as pd
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

#tsne libraries
from sklearn.manifold import TSNE
import seaborn as sns
from scipy.spatial.distance import squareform, pdist
import sklearn
from sklearn.datasets import load_digits
from sklearn.preprocessing import scale

from sklearn.metrics.pairwise import pairwise_distances
#from sklearn.utils.extmath import _ravel
# Random state we define this random state to use this value in TSNE which is a randmized algo.
RS = 25111993

# Importing matplotlib for graphics.
import matplotlib.pyplot as plt
import matplotlib.patheffects as PathEffects
import matplotlib
# %matplotlib inline

# Importing seaborn to make nice plots.
import seaborn as sns
sns.set_style('darkgrid')
sns.set_palette('muted')
sns.set_context("notebook", font_scale=1.5,
                rc={"lines.linewidth": 2.5})

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install git+https://github.com/openai/CLIP.git

testdata = CIFAR10('.', train=False, download=True)

import torch
import clip

device =  "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

img = [np.array(testdata[i][0]).flatten() for i in range(4000)]
lab = [testdata[i][1] for i in range(4000)]

# images = torch.vstack([preprocess(i).unsqueeze(0).to(device) for i in img])
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
# text = clip.tokenize(classes).to(device)

with torch.no_grad():
    # image_features = model.encode_image(images)
    image_features = np.vstack(img)

image_features.shape

kmeans = KMeans(n_clusters = 10).fit(image_features)#.cpu().numpy())
Y = kmeans.labels_

Y = cluster.labels_
z = pd.DataFrame(Y.tolist())
proj = TSNE(random_state=RS).fit_transform(image_features)#.cpu().numpy())

# udf to scatter vector plots
def scatter(x, colors):
  palette = np.array(sns.color_palette("hls", 10))
  f = plt.figure(figsize=(32, 32))
  ax = plt.subplot(aspect='equal')
  sc = ax.scatter(x[:, 0], x[:, 1], lw=0, s=120, 
                  c=palette[colors.astype(np.int)])
  ax.axis("tight")

  #labels for every cluster
  txts = []
  for i in range(10):
    xtext, ytext = np.median(x[colors == i, :], axis=0)
    txt = ax.text(xtext, ytext, str(i), fontsize=50)
    txt.set_path_effects([
        PathEffects.Stroke(linewidth=5, foreground="w"),
        PathEffects.Normal()])
    txts.append(txt)
  return f, ax, sc, txts

print(list(range(0, 18)))
sns.palplot(np.array(sns.color_palette("hls", 10)))
scatter(proj, Y)
plt.savefig("Naive Agglo clusters.png", dpi=120)



"""# HDBSCAN"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install hdbscan
# !pip install kneed

import hdbscan

embeds = image_features#.cpu()

clusterer = hdbscan.HDBSCAN(min_cluster_size=3, gen_min_span_tree=True)
clusterer.fit(embeds)

np.unique(clusterer.labels_)

"""# Agglomerative"""

from sklearn.cluster import AgglomerativeClustering

cluster = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')
cluster.fit_predict(embeds)

np.unique(cluster.labels_)